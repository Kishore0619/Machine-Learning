{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5747f4-75b3-4a0a-a381-ab12a1db0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from User_defined_Data_loader import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dl = DataLoader(\"restaurant_data.csv\")\n",
    "restaurant_data = dl.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2268cbe3-b586-419a-aa8a-8a9e32de8450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Seating Capacity</th>\n",
       "      <th>Average Meal Price</th>\n",
       "      <th>Marketing Budget</th>\n",
       "      <th>Social Media Followers</th>\n",
       "      <th>Chef Experience Years</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Avg Review Length</th>\n",
       "      <th>Ambience Score</th>\n",
       "      <th>Service Quality Score</th>\n",
       "      <th>Parking Availability</th>\n",
       "      <th>Weekend Reservations</th>\n",
       "      <th>Weekday Reservations</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Restaurant 0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38</td>\n",
       "      <td>73.98</td>\n",
       "      <td>2224</td>\n",
       "      <td>23406</td>\n",
       "      <td>13</td>\n",
       "      <td>185</td>\n",
       "      <td>161.924906</td>\n",
       "      <td>1.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>638945.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Restaurant 1</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>3.2</td>\n",
       "      <td>76</td>\n",
       "      <td>28.11</td>\n",
       "      <td>4416</td>\n",
       "      <td>42741</td>\n",
       "      <td>8</td>\n",
       "      <td>533</td>\n",
       "      <td>148.759717</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>490207.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Restaurant 2</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Italian</td>\n",
       "      <td>4.7</td>\n",
       "      <td>48</td>\n",
       "      <td>48.29</td>\n",
       "      <td>2796</td>\n",
       "      <td>37285</td>\n",
       "      <td>18</td>\n",
       "      <td>853</td>\n",
       "      <td>56.849189</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>541368.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Restaurant 3</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Italian</td>\n",
       "      <td>4.4</td>\n",
       "      <td>34</td>\n",
       "      <td>51.55</td>\n",
       "      <td>1167</td>\n",
       "      <td>15214</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>205.433265</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>404556.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Restaurant 4</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>4.9</td>\n",
       "      <td>88</td>\n",
       "      <td>75.98</td>\n",
       "      <td>3639</td>\n",
       "      <td>40171</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>241.681584</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>No</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>1491046.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  Location   Cuisine  Rating  Seating Capacity  \\\n",
       "0  Restaurant 0     Rural  Japanese     4.0                38   \n",
       "1  Restaurant 1  Downtown   Mexican     3.2                76   \n",
       "2  Restaurant 2     Rural   Italian     4.7                48   \n",
       "3  Restaurant 3     Rural   Italian     4.4                34   \n",
       "4  Restaurant 4  Downtown  Japanese     4.9                88   \n",
       "\n",
       "   Average Meal Price  Marketing Budget  Social Media Followers  \\\n",
       "0               73.98              2224                   23406   \n",
       "1               28.11              4416                   42741   \n",
       "2               48.29              2796                   37285   \n",
       "3               51.55              1167                   15214   \n",
       "4               75.98              3639                   40171   \n",
       "\n",
       "   Chef Experience Years  Number of Reviews  Avg Review Length  \\\n",
       "0                     13                185         161.924906   \n",
       "1                      8                533         148.759717   \n",
       "2                     18                853          56.849189   \n",
       "3                     13                 82         205.433265   \n",
       "4                      9                 78         241.681584   \n",
       "\n",
       "   Ambience Score  Service Quality Score Parking Availability  \\\n",
       "0             1.3                    7.0                  Yes   \n",
       "1             2.6                    3.4                  Yes   \n",
       "2             5.3                    6.7                   No   \n",
       "3             4.6                    2.8                  Yes   \n",
       "4             8.6                    2.1                   No   \n",
       "\n",
       "   Weekend Reservations  Weekday Reservations     Revenue  \n",
       "0                    13                     4   638945.52  \n",
       "1                    48                     6   490207.83  \n",
       "2                    27                    14   541368.62  \n",
       "3                     9                    17   404556.80  \n",
       "4                    37                    26  1491046.35  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5dcde9-05f3-434f-ad10-f8bb0839bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_data = restaurant_data.rename(\n",
    "    columns={\n",
    "        'Seating Capacity':'Seating_Capacity',\n",
    "        'Average Meal Price':'Average_Meal_Price', \n",
    "        'Marketing Budget':'Marketing_Budget', \n",
    "        'Social Media Followers':'Social_Media_Followers',\n",
    "        'Chef Experience Years':'Chef_Experience_Years', \n",
    "        'Number of Reviews':'Number_of_Reviews', \n",
    "        'Avg Review Length': 'AvgReviewLength',\n",
    "        'Ambience Score':'AmbienceScore', \n",
    "        'Service Quality Score':'ServiceQualityScore', \n",
    "        'Parking Availability':'ParkingAvailability',\n",
    "        'Weekend Reservations':'WeekendReservations', \n",
    "        'Weekday Reservations':'WeekdayReservations'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08646d05-68a3-49c8-a8b0-f2e5f726a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader('AirQualityUCI.csv')\n",
    "air_quality_data = dl.read_data(sep=';')\n",
    "air_quality_data.set_index('Date',inplace=True)\n",
    "air_quality_data['PT08.S5(O3)'].fillna(air_quality_data['PT08.S5(O3)'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ea5753-6c26-4546-a62a-df1a3c51a5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10/03/2004</th>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13,6</td>\n",
       "      <td>48,9</td>\n",
       "      <td>0,7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/03/2004</th>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13,3</td>\n",
       "      <td>47,7</td>\n",
       "      <td>0,7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/03/2004</th>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9,0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11,9</td>\n",
       "      <td>54,0</td>\n",
       "      <td>0,7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/03/2004</th>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9,2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11,0</td>\n",
       "      <td>60,0</td>\n",
       "      <td>0,7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/03/2004</th>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1,6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6,5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11,2</td>\n",
       "      <td>59,6</td>\n",
       "      <td>0,7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  PT08.S2(NMHC)  \\\n",
       "Date                                                                         \n",
       "10/03/2004  18.00.00    2,6       1360.0     150.0     11,9         1046.0   \n",
       "10/03/2004  19.00.00      2       1292.0     112.0      9,4          955.0   \n",
       "10/03/2004  20.00.00    2,2       1402.0      88.0      9,0          939.0   \n",
       "10/03/2004  21.00.00    2,2       1376.0      80.0      9,2          948.0   \n",
       "10/03/2004  22.00.00    1,6       1272.0      51.0      6,5          836.0   \n",
       "\n",
       "            NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T  \\\n",
       "Date                                                                          \n",
       "10/03/2004    166.0        1056.0    113.0        1692.0       1268.0  13,6   \n",
       "10/03/2004    103.0        1174.0     92.0        1559.0        972.0  13,3   \n",
       "10/03/2004    131.0        1140.0    114.0        1555.0       1074.0  11,9   \n",
       "10/03/2004    172.0        1092.0    122.0        1584.0       1203.0  11,0   \n",
       "10/03/2004    131.0        1205.0    116.0        1490.0       1110.0  11,2   \n",
       "\n",
       "              RH      AH  Unnamed: 15  Unnamed: 16  \n",
       "Date                                                \n",
       "10/03/2004  48,9  0,7578          NaN          NaN  \n",
       "10/03/2004  47,7  0,7255          NaN          NaN  \n",
       "10/03/2004  54,0  0,7502          NaN          NaN  \n",
       "10/03/2004  60,0  0,7867          NaN          NaN  \n",
       "10/03/2004  59,6  0,7888          NaN          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aa76a-102a-4ac1-bc2b-de7e96ead515",
   "metadata": {},
   "source": [
    "# 1. Parametric Statistical Hypothesis Tests\n",
    "Statistical Test for comaparison between data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ce441-96b5-41c3-982b-4508ebf7c3fc",
   "metadata": {},
   "source": [
    "## 1.1 One Sample T-Test\n",
    "mean of a sample is significantly different from a known population mean\n",
    "\n",
    "__H0: the mean of sample and population are Same.__\n",
    "\n",
    "__H1: the mean of sample and population are not Same.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57113f2-f070-4817-ba87-3f4eabd25f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "def one_sample_ttest(data,numeric_column):\n",
    "    sample_data = data[numeric_column].sample(500,random_state=1)\n",
    "    population_mean = data[numeric_column].mean()\n",
    "    t_static_value,p_value = ttest_1samp(sample_data,population_mean)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value>0.05:\n",
    "        print('Propably the mean of sample and population are same')\n",
    "    else:\n",
    "        print('Propably the mean of sample and population are not same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81737a3-4a39-40ad-9c74-7ed40f014433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:-1.464, P-Value:0.144\n",
      "Propably the mean of sample and population are same\n"
     ]
    }
   ],
   "source": [
    "one_sample_ttest(restaurant_data,numeric_column='Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd7cb2d-a3d6-433e-a3f8-009ead15ebe1",
   "metadata": {},
   "source": [
    "## 1.2 Two Sample T-Test\n",
    "Average Between two data samples are significantly different.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations are normally distributed.\n",
    "3. Observations have same variance between each other.\n",
    " \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the mean between two groups are equal.__\n",
    "\n",
    "__H1: the mean between two groups are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f39417-857a-4334-ae56-a611d40aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "def two_sample_ttest(numeric_column,category_column,data):\n",
    "    groups = data[category_column].unique().tolist()\n",
    "    group1 = data[data[category_column]==groups[0]][numeric_column].sample(500,random_state=1)\n",
    "    group2 = data[data[category_column]==groups[1]][numeric_column].sample(500,random_state=1)\n",
    "    t_static_value, p_value = ttest_ind(group1, group2)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably means between 2 groups are equal')\n",
    "    else:\n",
    "        print('Probably means between 2 groups are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de415b67-3d3c-4f7f-bd03-0030855c323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:0.105, P-Value:0.917\n",
      "Probably means between 2 groups are equal\n"
     ]
    }
   ],
   "source": [
    "two_sample_ttest(numeric_column='AvgReviewLength',category_column='Location',data=restaurant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152c0fc-9d3f-4482-b426-5de9201b8eae",
   "metadata": {},
   "source": [
    "## 1.3 Two sampled Paired t-test\n",
    "A paired samples t-test is used to test the means between the old and New values of the Features are same or not.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations are normally distributed.\n",
    "3. Observations have same variance between each other.\n",
    "4. Observations are paired.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: mean old and new values are equal.__\n",
    "\n",
    "__H1: mean old and new values are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a782477-87d1-4a9d-ba3c-3e5b57f1a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "def paired_ttest(numeric_column,category_column,data):\n",
    "    groups = data[category_column].unique().tolist()\n",
    "    new = data[data[category_column]==groups[0]][numeric_column].sample(500,random_state=1)\n",
    "    old = data[data[category_column]==groups[1]][numeric_column].sample(500,random_state=1)\n",
    "    t_static_value, p_value = ttest_rel(new, old)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably means of old and new sample data are equal')\n",
    "    else:\n",
    "        print('Probably means of old and new sample data are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29ad29d-bd35-40a7-b769-27692a081ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:-31.193, P-Value:0.000\n",
      "Probably means of old and new sample data are not equal\n"
     ]
    }
   ],
   "source": [
    "paired_ttest(data=restaurant_data,numeric_column='Revenue',category_column='Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23183f71-6a8d-4524-95b2-7a694e9fb5af",
   "metadata": {},
   "source": [
    "## 1.4 Z-test\n",
    "sample mean is significantly different from a known population mean\n",
    "\n",
    "__H0: the mean of sample and population are Same.__\n",
    "\n",
    "__H1: the mean of sample and population are not Same.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e42550b-11fe-4141-8874-9a3d640db5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def z_test(data,numerical_column,category_column):\n",
    "    \n",
    "    groups = data[category_column].unique().tolist()\n",
    "    sample_data = data[data[category_column]==groups[0]][numerical_column]\n",
    "    population_mean = data[numerical_column].mean()\n",
    "    \n",
    "    # Calculate the sample mean and standard deviation\n",
    "    sample_mean = np.mean(sample_data)\n",
    "    sample_std = np.std(sample_data)\n",
    "    \n",
    "    # Calculate the sample size\n",
    "    sample_size = len(sample_data)\n",
    "    # Calculate the standard error\n",
    "    standard_error = sample_std / (sample_size ** 0.5)\n",
    "    \n",
    "    # Calculate the Z-score\n",
    "    z_score = (sample_mean - population_mean) / standard_error\n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
    "    \n",
    "    print(f'Z-Score:{z_score:.3f}, P-Value:{p_value:.3f}')   \n",
    "    \n",
    "    if p_value>0.05:\n",
    "        print('Propably the mean of sample and population are same')\n",
    "    else:\n",
    "        print('Propably the mean of sample and population are not same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bcffce-df32-4a5a-b04f-9ee0e403e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score:-75.539, P-Value:0.000\n",
      "Propably the mean of sample and population are not same\n"
     ]
    }
   ],
   "source": [
    "z_test(restaurant_data,'Revenue','Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a46955-1eee-4fde-a98f-57fd411d4be7",
   "metadata": {},
   "source": [
    "## 1.5 Analysis of Variance Test (ANOVA)\n",
    "test whether there are significant differences between the means of two or more groups.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations are normally distributed.\n",
    "3. Observations have same variance between each other.\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the means between two or more groups are equal.__\n",
    "\n",
    "__H1: the means between two or more groups are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850bd1d7-7e75-4864-a319-74d7c7720682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "\n",
    "def anova_one_way(data,category_column,numeric_column):\n",
    "    groups = data[category_column].unique().tolist()\n",
    "    group_data = []\n",
    "    for i in groups:\n",
    "        group_data.append(data[data[category_column]==i][numeric_column].tolist())\n",
    "    \n",
    "    t_static_value, prob_val = f_oneway(*group_data)    \n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{prob_val:.3f}')\n",
    "    if prob_val > 0.05:\n",
    "        print(f'Probably means of {len(groups)} groups are equal')\n",
    "    else:\n",
    "        print(f'Probably means of {len(groups)} groups are not equal')\n",
    "        mc = MultiComparison(data[numeric_column], data[category_column])\n",
    "        result = mc.tukeyhsd()\n",
    "        print(result)\n",
    "        print(mc.groupsunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fd9bb8d-1c06-4751-a74c-e9b0c8890b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:2847.437, P-Value:0.000\n",
      "Probably means of 3 groups are not equal\n",
      "        Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "====================================================================\n",
      " group1   group2    meandiff  p-adj    lower        upper     reject\n",
      "--------------------------------------------------------------------\n",
      "Downtown    Rural -416424.035   0.0 -429368.3159 -403479.7542   True\n",
      "Downtown Suburban -219532.464   0.0  -232449.709  -206615.219   True\n",
      "   Rural Suburban 196891.5711   0.0  183905.9675  209877.1746   True\n",
      "--------------------------------------------------------------------\n",
      "['Downtown' 'Rural' 'Suburban']\n"
     ]
    }
   ],
   "source": [
    "anova_one_way(restaurant_data,category_column='Location',numeric_column='Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424b61b-7119-4db2-9829-9e8db93a9067",
   "metadata": {},
   "source": [
    "## 1.6 Multivarite Analysis of variance (MANOVA)\n",
    "Average between two or more paired samples are significantly different.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations are normally distributed.\n",
    "3. Observations have same variance between each other.\n",
    "4. Observation can be paired.\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: means of two or more groups on multiple independent variables are Equal.__\n",
    "\n",
    "__H1: means of two or more groups on multiple independent variables are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4860c8ff-50a1-4cb3-95d8-29064a598222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.multivariate.manova import MANOVA\n",
    "def manova_test(numerical_column1,numerical_column2,numerical_column3,categorical_column,data):\n",
    "    user_formula =f'{numerical_column1} + {numerical_column2} + {numerical_column3} ~ {categorical_column}'\n",
    "    manova_t = MANOVA.from_formula(formula=user_formula,data=data)\n",
    "    p_value = manova_t.mv_test().results[categorical_column]['stat']['Pr > F'][0]\n",
    "    print(f\"P-value: {p_value:.3f}\")\n",
    "    if p_value > 0.05:\n",
    "        print('Probably, means of two or more groups on multiple independent variables are Equal')\n",
    "    else:\n",
    "        print('Probably, means of two or more groups on multiple independent variables are Not Equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec524ec-c21e-40dc-b804-25617340dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.000\n",
      "Probably, means of two or more groups on multiple independent variables are Not Equal\n"
     ]
    }
   ],
   "source": [
    "result = manova_test(\n",
    "    numerical_column1='Average_Meal_Price',\n",
    "    numerical_column2='AvgReviewLength',\n",
    "    numerical_column3='Revenue',\n",
    "    categorical_column='Location',\n",
    "    data=restaurant_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45bfc70-c8ac-4461-bb4a-cd61bc74b315",
   "metadata": {},
   "source": [
    "# 2. Nonparametric Statistical Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be1a5a-d722-4d3d-babd-f52907e29aad",
   "metadata": {},
   "source": [
    "## 2.1 Mann-Whitney U Test\n",
    "Distribution of two data samples are equal or not. And, used for independent samples\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations in each data samples can be ranked.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the distribution of two samples are equal.__\n",
    "\n",
    "__H1: the distribution of two samples are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a7c940b-45af-4434-9932-84e67b0eaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def mann_whitney_test(data1,data2):\n",
    "    t_static_value, p_value= mannwhitneyu(data1, data2)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Distributions of two samples are equal')\n",
    "    else:\n",
    "        print(f'Distributions of two samples are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce53984-3dbb-4061-b6b0-3004246974ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:0.000, P-Value:0.000\n",
      "Distributions of two samples are not equal\n"
     ]
    }
   ],
   "source": [
    "mann_whitney_test(restaurant_data['Average_Meal_Price'],restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294896e-59af-40d1-a472-892c87b48df2",
   "metadata": {},
   "source": [
    "## 2.2 Wilcoxon Signed-Rank Test\n",
    "Distribution between two paired samples are significantly equal or not. And, used for related samples\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations can be ranked.\n",
    "3. Observations are paired.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the distribution of two samples are equal.__\n",
    "\n",
    "__H1: the distribution of two samples are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a73ebcf-a46f-4d81-a965-9058d9a72bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Wilcoxon Signed-Rank Test\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def wilcoxon_test(numerical_column,category_column,data):\n",
    "    groups = data[category_column].unique().tolist()\n",
    "    group1 = data[data[category_column]==groups[0]][numerical_column].sample(500,random_state=1)\n",
    "    group2 = data[data[category_column]==groups[1]][numerical_column].sample(500,random_state=1)\n",
    "    t_static_value, p_value= wilcoxon(group1, group2)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Distributions of two paired samples are equal')\n",
    "    else:\n",
    "        print(f'Distributions of two paired samples are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de57878b-d477-432f-aad1-d7b688c4a6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:2455.000, P-Value:0.000\n",
      "Distributions of two paired samples are not equal\n"
     ]
    }
   ],
   "source": [
    "wilcoxon_test(numerical_column='Revenue',category_column='Location',data=restaurant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d32b4-e152-4dad-857a-29756817ec12",
   "metadata": {},
   "source": [
    "## 2.3 Kruskal-Wallis H Test\n",
    "Distribution between two or more independent samples are significantly equal or not. And, used for independent samples.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations can be ranked.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the distribution of samples are equal.__\n",
    "\n",
    "__H1: the distribution of samples are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d68d14-ef7e-4cf4-84a8-978725cdf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "def kruskal_test(data,category_column,numeric_column):\n",
    "    groups = data[category_column].unique().tolist()\n",
    "    group_data = []\n",
    "    for i in groups:\n",
    "        group_data.append(data[data[category_column]==i][numeric_column].tolist())\n",
    "    \n",
    "    t_static_value, p_value = kruskal(*group_data)    \n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Distributions of two or more groups samples are equal')\n",
    "    else:\n",
    "        print(f'Distributions of two or more groups samples are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5afb1317-c0b9-4bd1-975c-4289b66eb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:9.061, P-Value:0.011\n",
      "Distributions of two or more groups samples are not equal\n"
     ]
    }
   ],
   "source": [
    "kruskal_test(data=restaurant_data,category_column='Location',numeric_column='AvgReviewLength')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcf372-0fba-44d5-aa4e-49d4abfb50df",
   "metadata": {},
   "source": [
    "## 2.4 Friedman Test\n",
    "Distribution between two or more paired samples are significantly equal or not.\n",
    "\n",
    "__Assumption__\n",
    "1. Each data sample's observation are independent and distributed.\n",
    "2. Observations can be ranked.\n",
    "3. Observations can be paired.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the distribution of all samples are equal.__\n",
    "\n",
    "__H1: the distribution of one or more samples are not equal.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826f84b6-a0db-4b02-a626-9cf5abec3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "def friedman_test(data1,data2,data3):\n",
    "    t_static_value, p_value= friedmanchisquare(data1, data2, data3)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Distributions of two or more independent samples are equal')\n",
    "    else:\n",
    "        print(f'Distributions of two or more independent samples are not equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d659760-d7ea-48d7-86ea-523d0552b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:16395.236, P-Value:0.000\n",
      "Distributions of two or more independent samples are not equal\n"
     ]
    }
   ],
   "source": [
    "friedman_test(restaurant_data['Average_Meal_Price'],restaurant_data['AvgReviewLength'],restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebba7f5-9206-422e-aea8-e5c2759adaca",
   "metadata": {},
   "source": [
    "# 3. Correlation Tests\n",
    "Correlation Tests are used to check the correlation between two independent features or variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb7348-3c02-4904-82e7-cbf81caa6991",
   "metadata": {},
   "source": [
    "## 3.1 Pearson’s Correlation Coefficient\n",
    "Tests whether a data features is linearly separable.\n",
    "\n",
    "__Assumption__\n",
    "1. Observations in each sample are independent and distributed identically.\n",
    "2. Observations are normally distributed.\n",
    "3. Similar variance between independent variables\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Fetaures are correlated.__\n",
    "\n",
    "__H1: Features does not have any correlation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002aaf0a-448d-4d9e-8f60-23ca008d2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearsons_correlation(data1,data2):\n",
    "    t_static_value,p_value = pearsonr(data1,data2)\n",
    "    print(f'T-static-Value:{t_static_value:.3f}, P-Value:{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Probably Features are Correlated')\n",
    "    else:\n",
    "        print(f'Probably Features may not have any correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba08e242-b1bb-44df-ad0d-4e7f85b20043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-Value:0.686, P-Value:0.000\n",
      "Probably Features may not have any correlation\n"
     ]
    }
   ],
   "source": [
    "pearsons_correlation(restaurant_data['Average_Meal_Price'],restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45694c-3544-420d-a828-f31054100d1f",
   "metadata": {},
   "source": [
    "## 3.2 Spearman’s Rank Correlation\n",
    "Tests whether a data sample is montonically separable.\n",
    "\n",
    "__Assumption__\n",
    "1. Observations in each sample are independent and distributed identically.\n",
    "2. Observations in each sample are ranked.\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the samples are correlated.__\n",
    "\n",
    "__H1: the sample does not have any correlation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "230731ba-52b9-479f-9f60-775561bd36e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def spearmans_correlation(data1,data2):\n",
    "    t_static_value,p_value = spearmanr(data1,data2)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Probably Features are Correlated')\n",
    "    else:\n",
    "        print(f'Probably Features may not have any correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8824bc2-7532-4190-ac36-432e72928be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 0.680, P-value :0.000\n",
      "Probably Features may not have any correlation\n"
     ]
    }
   ],
   "source": [
    "spearmans_correlation(restaurant_data['Average_Meal_Price'],restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886e683-78a9-4781-8b73-1e402cd1a839",
   "metadata": {},
   "source": [
    "## 3.3 Kendall’s Rank Correlation\n",
    "Tests whether a data sample is montonically separable.\n",
    "\n",
    "__Assumption__\n",
    "1. Observations in each sample are independent and distributed identically.\n",
    "2. Observations in each sample are ranked.\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the samples are correlated.__\n",
    "\n",
    "__H1: the sample does not have any correlation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f527c4c-ef70-47df-9f17-5968e4d99054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "def kendalls_correlation(data1,data2):\n",
    "    t_static_value,p_value = kendalltau(data1,data2)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Probably Features are Correlated')\n",
    "    else:\n",
    "        print(f'Probably Features may not have any correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c83640a1-ce3a-4455-83e7-7437cf4d9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 0.487, P-value :0.000\n",
      "Probably Features may not have any correlation\n"
     ]
    }
   ],
   "source": [
    "kendalls_correlation(restaurant_data['Average_Meal_Price'],restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee38b41-64b0-47d9-8583-7ff25928d38a",
   "metadata": {},
   "source": [
    "## 3.4 Chi-Squared Test\n",
    "Tests whether two categorical variables are related to each other.\n",
    "\n",
    "__Assumption__\n",
    "1. Observations in used in contengency table are Independent.\n",
    "2. There are more than 25 examples in contengency table .\n",
    "   \n",
    "__Hypothesis__\n",
    "\n",
    "__H0: probably two categorical features are correlated.__\n",
    "\n",
    "__H1: probably two categorical features may does not have any correlation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77a8bc3-3762-4e79-8a35-ea4b68876209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "def chi2_test(category_data1,category_data2):\n",
    "    cross_table = pd.crosstab(category_data1,category_data2)\n",
    "    chi,p_value,dof,expected=chi2_contingency(cross_table)\n",
    "    print(f'Chi-Square-value : {chi:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print(f'Probably Features are Correlated')\n",
    "    else:\n",
    "        print(f'Probably Features may not have any correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4964b207-4ad5-442a-b762-f3ce1b99c9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square-value : 15.593, P-value :0.112\n",
      "Probably Features are Correlated\n"
     ]
    }
   ],
   "source": [
    "chi2_test(restaurant_data['Location'],restaurant_data['Cuisine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b1a36-8763-4c6e-acb2-1443deefcfef",
   "metadata": {},
   "source": [
    "# 4. Normality Tests\n",
    "Main obejctive of performing Normality Tests is to validate the Normal distribution of data.\n",
    "\n",
    "## 4.1 Shapiro-Wilk Test\n",
    "Tests whether a data sample has a Normal distribution.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Observations in each sample are independent and distributed identically.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the sample has a Normal distribution.__\n",
    "\n",
    "__H1: the sample does not have a Normal distribution.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e51332e-2b19-426b-b33d-aa51af37ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def shapiro_wilk_test(numeric_data):\n",
    "    t_static_value, p_value = shapiro(numeric_data)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably Normal Distribution')\n",
    "    else:\n",
    "        print('Probably not a Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4151b69-1074-4c6c-b5ea-5104c2e1b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 0.953, P-value :0.000\n",
      "Probably not a Normal Distribution\n"
     ]
    }
   ],
   "source": [
    "shapiro_wilk_test(restaurant_data['Revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a20db4-adbc-464c-b514-f627026e291d",
   "metadata": {},
   "source": [
    "## 4.2 D'Agostino-Pearson Test\n",
    "tests the skewness and kurtosis of the data to test for normality.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Observations in each sample are independent and distributed identically.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the sample has a Normal distribution.__\n",
    "\n",
    "__H1: the sample does not have a Normal distribution.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9303928-5ddd-406c-8634-e2f800d43dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "def d_agostino_test(data):\n",
    "    t_static_value,p_value = normaltest(data)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably Normal Distribution')\n",
    "    else:\n",
    "        print('Probably not a Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df017dd1-43f2-4b10-8793-1467da871cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 7096.180, P-value :0.000\n",
      "Probably not a Normal Distribution\n"
     ]
    }
   ],
   "source": [
    "d_agostino_test(restaurant_data['AvgReviewLength'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a7011-5049-48ff-aed5-a8610a408e4e",
   "metadata": {},
   "source": [
    "## 4.3 Anderson-Darling Test\n",
    "Tests whether a data sample has a Normal distribution.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Observations in each sample are independent and distributed identically.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the sample has a Normal distribution.__\n",
    "\n",
    "__H1: the sample does not have a Normal distribution.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0d32f60-275f-4e7a-a069-5da201e8d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import anderson\n",
    "\n",
    "def anderson_darling_test(data):\n",
    "    result = anderson(data,dist='norm')\n",
    "    \n",
    "    # get the critical value for the chosen significance level 5%\n",
    "    critical_value = result.critical_values[result.significance_level == 5]\n",
    "    print(f'T-static-value : {result.statistic:.3f}, Critical-Value :{critical_value}')\n",
    "    # if the test statistic is greater than the critical value, reject the null Hypothesis__\n",
    "    if result.statistic > critical_value:\n",
    "        print(\"The data is not normally distributed.\")\n",
    "    else:\n",
    "        print(\"The data is normally distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "753b90de-5b99-4d82-9406-5ff0fefbfdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 154.289, Critical-Value :[0.787]\n",
      "The data is not normally distributed.\n"
     ]
    }
   ],
   "source": [
    "anderson_darling_test(restaurant_data['Average_Meal_Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0e1d6-c67d-42b5-81e9-f2d52d2476d4",
   "metadata": {},
   "source": [
    "## 4.4 Kolmogorov-Smirnov Test\n",
    "This test compares the empirical distribution function of the data to a specified theoretical distribution (in this case, a normal distribution)\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Observations in each sample are independent and distributed identically.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: the sample has a Normal distribution.__\n",
    "\n",
    "__H1: the sample does not have a Normal distribution.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcc95bfd-6a3c-4de5-b701-28c5edc23b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "def kolmogorov_test(data):\n",
    "    t_static_value,p_value = kstest(data,'norm')\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably Normal Distribution')\n",
    "    else:\n",
    "        print('Probably not a Normal Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95250695-37a7-4f5f-9862-ff3c96cbe5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 1.000, P-value :0.000\n",
      "Probably not a Normal Distribution\n"
     ]
    }
   ],
   "source": [
    "kolmogorov_test(restaurant_data['Average_Meal_Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e674f-74b0-4edb-95ff-8f29a3b162a6",
   "metadata": {},
   "source": [
    "# 5. Stationary Tests\n",
    "Used for Validating the Time series data trends(Stationary/Not-Stationary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c1ad6-e7d1-4cac-b67f-792092382164",
   "metadata": {},
   "source": [
    "## 5.1 Augmented Dickey-Fuller Unit Root Test\n",
    "Tests whether a Time series data has autoregressive trend.\n",
    "\n",
    "__Assumption__\n",
    "Data Instance have temporality.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Time series is Stationary.__\n",
    "\n",
    "__H1: Time series is not stationary.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0736c39f-2185-499b-85eb-a4afebbb3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Augmented Dickey-Fuller unit root test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def augmented_DFU_roottest(data):\n",
    "    t_static_value, p_value, lags, obs, crit, t = adfuller(data)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably Stationary')\n",
    "    else:\n",
    "        print('Probably not Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0ee3762-ab0b-4af1-89ac-5256cf4b097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : -11.458, P-value :0.000\n",
      "Probably not Stationary\n"
     ]
    }
   ],
   "source": [
    "augmented_DFU_roottest(air_quality_data['PT08.S5(O3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f22440-55a3-4b5e-87b8-3ccc7b961b3e",
   "metadata": {},
   "source": [
    "## 5.2 Kwiatkowski-Phillips-Schmidt-Shin\n",
    "Tests whether a Time series trend is stationary or not.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Data Instance have temporality.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Time Series is Stationary.__\n",
    "\n",
    "__H1: Time Series is not stationary.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bac042f-2750-4c99-98cd-2639b0d0cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def kwiatkowski_test(data):\n",
    "    t_static_value, p_value, lags, obs = kpss(data)\n",
    "    print(f'T-static-value : {t_static_value:.3f}, P-value :{p_value:0.3f}')\n",
    "    if p_value > 0.05:\n",
    "        print('Probably Stationary')\n",
    "    else:\n",
    "        print('Probably not Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51ab12ce-77e3-4a0f-a8a4-3cd068018a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 0.345, P-value :0.100\n",
      "Probably Stationary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kishore.thirunagari\\AppData\\Local\\Temp\\ipykernel_24096\\4162121527.py:4: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is greater than the p-value returned.\n",
      "\n",
      "  t_static_value, p_value, lags, obs = kpss(data)\n"
     ]
    }
   ],
   "source": [
    "kwiatkowski_test(air_quality_data['PT08.S5(O3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779bb68-198d-4bc2-b5b1-475c9b062867",
   "metadata": {},
   "source": [
    "## 5.3 Philips-Perron (PP) Test\n",
    "Tests whether a Time series trend is stationary or not.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Data Instance have temporality.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Time Series is Stationary.__\n",
    "\n",
    "__H1: Time Series is not stationary.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18eb8334-7bc7-4abf-a07c-6d32d86842b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.unitroot import PhillipsPerron\n",
    "\n",
    "def pp_test(data):\n",
    "    test_result = PhillipsPerron(data)\n",
    "    print(f'T-static-value : {test_result.stat:.3f}, P-value :{test_result.pvalue:0.3f}')\n",
    "    if test_result.pvalue > 0.05:\n",
    "        print('Probably Stationary')\n",
    "    else:\n",
    "        print('Probably not Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f05bfc6-cc46-4ddb-8b98-e1597622373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : -22.255, P-value :0.000\n",
      "Probably not Stationary\n"
     ]
    }
   ],
   "source": [
    "pp_test(air_quality_data['PT08.S5(O3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7a1a1-5f3b-4e7a-960e-df268267fb86",
   "metadata": {},
   "source": [
    "## 5.4 Hurst Exponent\n",
    "Tests whether a Time series trend is stationary or not.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Data Instance have temporality.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Time Series is Stationary.__\n",
    "\n",
    "__H1: Time Series is not stationary.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b719eec3-0ca9-4f95-a1a1-e915ed73cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nolds import hurst_rs\n",
    "\n",
    "def hurst_exponent(data):\n",
    "    h = hurst_rs(data)\n",
    "    # Print Hurst exponent\n",
    "    print('Hurst Exponent: %0.3f' %h)\n",
    "    if h > 0.5:\n",
    "        print('Probably Stationary')\n",
    "    else:\n",
    "        print('Probably not Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ae80121-cc83-4aa5-938b-eb3911e5821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurst Exponent: 0.840\n",
      "Probably Stationary\n"
     ]
    }
   ],
   "source": [
    "hurst_exponent(air_quality_data['PT08.S5(O3)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba87391-16ab-41b6-b86f-22a8e54421b6",
   "metadata": {},
   "source": [
    "## 5.5 Variance Ratio Test\n",
    "Tests whether a Time series trend is stationary or not.\n",
    "\n",
    "__Assumption__\n",
    "\n",
    "Data Instance have temporality.\n",
    "\n",
    "__Hypothesis__\n",
    "\n",
    "__H0: Time Series is Stationary.__\n",
    "\n",
    "__H1: Time Series is not stationary.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b83313b1-42a8-4753-a9c7-496cbb3a65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.unitroot import VarianceRatio\n",
    "\n",
    "def variance_ratio_test(data):\n",
    "    # Perform variance ratio test\n",
    "    test_result = VarianceRatio(data)\n",
    "    print(f'T-static-value : {test_result.stat:.3f}, P-value :{test_result.pvalue:0.3f}')\n",
    "    if test_result.pvalue > 0.05:\n",
    "        print('Probably Stationary')\n",
    "    else:\n",
    "        print('Probably not Stationary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af50a417-e1ae-4238-a0b2-00cd609257bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-static-value : 10.523, P-value :0.000\n",
      "Probably not Stationary\n"
     ]
    }
   ],
   "source": [
    "variance_ratio_test(air_quality_data['PT08.S5(O3)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
